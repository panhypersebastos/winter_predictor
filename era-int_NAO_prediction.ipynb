{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAO Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap, addcyclic, shiftgrid\n",
    "import pymongo\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timedelta, date\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.linear_model as skl_lm\n",
    "import gdal as gdl\n",
    "import matplotlib.mlab as ml\n",
    "import cartopy.crs as ccrs\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True) # for live plot\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_host_local = 'mongodb://localhost:27017/'\n",
    "mg = pymongo.MongoClient(mongo_host_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system.indexes',\n",
       " 'ERAINT_grid',\n",
       " 'ERAINT_lores_grid',\n",
       " 'ERAINT_lores_monthly_anom',\n",
       " 'ERAINT_monthly',\n",
       " 'ERAINT_lores_monthly']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = mg.ECMWF\n",
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA_vers = 'lores'\n",
    "if (ERA_vers == 'hires'):\n",
    "    col_dat = 'ERAINT_monthly'\n",
    "    col_anom = 'ERAINT_monthly_anom'\n",
    "    col_grid = 'ERAINT_grid'\n",
    "    resolution = 0.25\n",
    "elif (ERA_vers == 'lores'):\n",
    "    col_dat = 'ERAINT_lores_monthly'\n",
    "    col_anom = 'ERAINT_lores_monthly_anom'\n",
    "    col_grid = 'ERAINT_lores_grid'\n",
    "    resolution = 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct NAO index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query grid cells for NAO calculation\n",
    "con_grid = db[col_grid]\n",
    "poly1 = [list(reversed([ [-50,25], [-50,55], [10,55],[ 10,25], [-50,25]]))]\n",
    "poly2 = [list(reversed([ [-40, 55], [-40, 85], [20, 85], [20, 55], [-40, 55]]))]\n",
    "def getGridIds(this_polygon):\n",
    "    geo_qry = {\"loc\": \n",
    "               {\"$geoWithin\": {\n",
    "                   \"$geometry\": {\n",
    "                       \"type\": \"Polygon\",\n",
    "                       \"coordinates\": this_polygon\n",
    "                   }\n",
    "               }}}\n",
    "\n",
    "    res = con_grid.find(filter = geo_qry, projection = {\"_id\":0, \"id_grid\": 1, \"loc\": 1})\n",
    "    grid_df = pd.DataFrame(list(res))\n",
    "    return grid_df\n",
    "grid_df1 = getGridIds(poly1)\n",
    "grid_ids1 = grid_df1.id_grid.values\n",
    "grid_df2 = getGridIds(poly2)\n",
    "grid_ids2 = grid_df2.id_grid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   wyear        msl1  month        msl2         NAO\n",
       "1   1980  152.977452    5.0  -98.370800 -251.348252\n",
       "2   1981 -444.747185    5.0  117.529424  562.276609\n",
       "3   1982  336.279706    5.0 -377.140170 -713.419876\n",
       "4   1983 -342.535287    5.0  378.676276  721.211563\n",
       "5   1984 -220.904942    5.0  330.200922  551.105864"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get yearly DJF averages over the two NAO nodal locations\n",
    "\n",
    "con_anom = db[col_anom]\n",
    "\n",
    "def setWinterYear(date): # December belong to next year's winter\n",
    "    mon=date.month\n",
    "    yr=date.year\n",
    "    if mon >= 9:\n",
    "        res = yr+1\n",
    "    else:\n",
    "        res = yr\n",
    "    return res\n",
    "\n",
    "def getMSL(this_grid_ids):\n",
    "    this_msl = con_anom.aggregate(pipeline=[\n",
    "        {\"$match\": {\"id_grid\": {\"$in\": this_grid_ids.tolist()}}},\n",
    "        {\"$group\": {\"_id\": \"$date\", \"mean\": {\"$avg\": \"$msl\"} }},\n",
    "        {\"$project\": {\"date\": \"$_id\", \n",
    "                      \"_id\": 0, \n",
    "                      \"msl\": \"$mean\"}}])\n",
    "    this_msl_df = pd.DataFrame(list(this_msl))\n",
    "    this_msl_df = this_msl_df.assign(\n",
    "            month=list(map(lambda x: x.month, this_msl_df.date)),\n",
    "            wyear=list(map(lambda x: setWinterYear(x), this_msl_df.date)) ).pipe(\n",
    "    lambda df: df.query(\"month in [12, 1, 2]\") ).pipe(\n",
    "    lambda df: df.groupby(\"wyear\").mean().reset_index())\n",
    "    return this_msl_df\n",
    "    \n",
    "msl1_df = getMSL(this_grid_ids = grid_ids1).rename(columns={'msl': 'msl1'})\n",
    "msl2_df = getMSL(this_grid_ids = grid_ids2).rename(columns={'msl': 'msl2'})\n",
    "msl_df = pd.merge(msl1_df, msl2_df)\n",
    "msl_df = msl_df.assign(NAO = msl_df.msl2-msl_df.msl1).sort_values('wyear', ascending=True).reset_index(drop=True)\n",
    "# Get rid of the first year (1979) and the last (2017) because the winter month are not complete\n",
    "msl_df = msl_df.query(\"(wyear > 1979) & (wyear <2017)\")\n",
    "msl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "scatter",
         "x": [
          1980,
          1981,
          1982,
          1983,
          1984,
          1985,
          1986,
          1987,
          1988,
          1989,
          1990,
          1991,
          1992,
          1993,
          1994,
          1995,
          1996,
          1997,
          1998,
          1999,
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016
         ],
         "y": [
          -251.34825248225582,
          562.276609059571,
          -713.419875834828,
          721.2115632913301,
          551.105864494568,
          -728.6565991592656,
          -840.4751166878566,
          -477.1464378799178,
          -381.828063969006,
          1169.6934788523786,
          456.3908207136145,
          309.47947302857085,
          742.0941674893827,
          930.4713397278456,
          -191.58898900219012,
          593.1495843272426,
          -812.9905166314677,
          -168.12192234993302,
          -261.9483325857419,
          428.4064614704637,
          784.9275600972778,
          -672.40261551939,
          35.36866434523139,
          -464.76934788096713,
          -401.22064519898043,
          687.5425087221288,
          -230.19994498798036,
          243.7674844367353,
          427.95328496056953,
          -174.1444889040695,
          -1757.6197613460076,
          -717.6267005305241,
          825.963655192083,
          -742.5948847676126,
          -9.52146754940486,
          895.3481528221511,
          154.93704653447963
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"93c1ed44-34fb-478a-b691-a8bf31d61af1\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"93c1ed44-34fb-478a-b691-a8bf31d61af1\", [{\"type\": \"scatter\", \"x\": [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016], \"y\": [-251.34825248225582, 562.276609059571, -713.419875834828, 721.2115632913301, 551.105864494568, -728.6565991592656, -840.4751166878566, -477.1464378799178, -381.828063969006, 1169.6934788523786, 456.3908207136145, 309.47947302857085, 742.0941674893827, 930.4713397278456, -191.58898900219012, 593.1495843272426, -812.9905166314677, -168.12192234993302, -261.9483325857419, 428.4064614704637, 784.9275600972778, -672.40261551939, 35.36866434523139, -464.76934788096713, -401.22064519898043, 687.5425087221288, -230.19994498798036, 243.7674844367353, 427.95328496056953, -174.1444889040695, -1757.6197613460076, -717.6267005305241, 825.963655192083, -742.5948847676126, -9.52146754940486, 895.3481528221511, 154.93704653447963]}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"93c1ed44-34fb-478a-b691-a8bf31d61af1\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"93c1ed44-34fb-478a-b691-a8bf31d61af1\", [{\"type\": \"scatter\", \"x\": [1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016], \"y\": [-251.34825248225582, 562.276609059571, -713.419875834828, 721.2115632913301, 551.105864494568, -728.6565991592656, -840.4751166878566, -477.1464378799178, -381.828063969006, 1169.6934788523786, 456.3908207136145, 309.47947302857085, 742.0941674893827, 930.4713397278456, -191.58898900219012, 593.1495843272426, -812.9905166314677, -168.12192234993302, -261.9483325857419, 428.4064614704637, 784.9275600972778, -672.40261551939, 35.36866434523139, -464.76934788096713, -401.22064519898043, 687.5425087221288, -230.19994498798036, 243.7674844367353, 427.95328496056953, -174.1444889040695, -1757.6197613460076, -717.6267005305241, 825.963655192083, -742.5948847676126, -9.52146754940486, 895.3481528221511, 154.93704653447963]}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ts\n",
    "data = [go.Scatter(x=msl_df['wyear'], y=msl_df['NAO'] )]\n",
    "py.iplot(data, filename='pandas-time-series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query anomalies for a variable for each input grid cells\n",
    "def queryAnom(this_variable, this_grid_df):\n",
    "    # Query data anomalies\n",
    "    grid_ids = this_grid_df.id_grid.values\n",
    "    res = con_anom.aggregate(pipeline=[ \n",
    "    {\"$project\": {\"id_grid\": 1, \"date\": 1, this_variable: 1, \"month\": {\"$month\": \"$date\"}}},\n",
    "    {\"$match\": {\"month\": {\"$in\": [9, 10, 11, 12, 1, 2]},\n",
    "                \"id_grid\": {\"$in\": grid_ids.tolist()} }},\n",
    "    {\"$project\": {\"_id\": 0, \"id_grid\": 1, \"date\": 1, this_variable: 1}} ])    \n",
    "    anom_df = pd.DataFrame(list(res))\n",
    "    return anom_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date      Nino\n",
       "0 1979-01-01  0.149061\n",
       "1 1979-02-01  0.114270\n",
       "2 1979-09-01 -0.320141\n",
       "3 1979-10-01 -0.224291\n",
       "4 1979-11-01 -0.295341"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Region to retrieve Niño 3.4 index for SST\n",
    "# Niño 3.4 region: stretches from the 120th to 170th meridians west longitude astride \n",
    "# the equator five degrees of latitude on either side (Wikipedia)\n",
    "poly_Nino = [list(reversed([ [-170,-5], [-170,5],[-120,5], [-120,-5], [-170,-5]]))]\n",
    "grid_df_Nino = getGridIds(poly_Nino)\n",
    "grid_ids_Nino = grid_df_Nino.id_grid.values\n",
    "anom_sst_df = queryAnom(this_variable='sst', this_grid_df=grid_df_Nino)\n",
    "nino_df0 = anom_sst_df[['date', 'sst']].groupby('date').mean().reset_index().rename(columns={'sst':'Nino'})\n",
    "nino_df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get PCA scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic function to query grid ids above a given latitude\n",
    "def genCircle(start_lon, stop_lon, lat, decreasing): \n",
    "    res = map(lambda x:[int(x), lat],\n",
    "              sorted(np.arange(start=start_lon, stop=stop_lon+1), reverse=decreasing))\n",
    "    return list(res)\n",
    "\n",
    "def queryGrids(aboveLat):\n",
    "    this_box = {'lonmin': -180, 'lonmax': 180, 'latmin': aboveLat, 'latmax': 90}\n",
    "    circle_north_pos = genCircle(start_lon = this_box['lonmin'], stop_lon = this_box['lonmax'], \n",
    "                                  lat = this_box['latmax'], decreasing = False)\n",
    "    circle_south_neg = genCircle(start_lon = this_box['lonmin'], stop_lon = this_box['lonmax'], \n",
    "                                lat = this_box['latmin'],  decreasing = True)\n",
    "    slp_poly = [[this_box['lonmin'], this_box['latmin']]]\n",
    "    slp_poly.extend(circle_north_pos)\n",
    "    slp_poly.extend(circle_south_neg)\n",
    "    this_polygon = slp_poly\n",
    "    \n",
    "    if aboveLat > 0:\n",
    "        geo_qry = {\"loc\": \n",
    "               {\"$geoWithin\": {\n",
    "                   \"$geometry\": {\n",
    "                       \"type\": \"Polygon\",\n",
    "                       \"coordinates\": [this_polygon]\n",
    "               }}}}\n",
    "    else: # case of a big polygon larger than one hemisphere\n",
    "        geo_qry = {\"loc\": \n",
    "               {\"$geoWithin\": {\n",
    "                   \"$geometry\": {\n",
    "                       \"type\": \"Polygon\",\n",
    "                       \"coordinates\": [list(reversed(this_polygon))], # the orientation matters\n",
    "                       \"crs\": {\n",
    "                           \"type\": \"name\", \n",
    "                           \"properties\": { \"name\": \"urn:x-mongodb:crs:strictwinding:EPSG:4326\" }\n",
    "                       }\n",
    "                   }\n",
    "               }}}\n",
    "        \n",
    "    res = con_grid.find(filter = geo_qry, projection = {\"_id\":0, \"id_grid\": 1, \"loc\": 1})\n",
    "    grid_df = pd.DataFrame(list(res))\n",
    "    return grid_df\n",
    "\n",
    "grid_df_20N = queryGrids(aboveLat=20)\n",
    "grid_df_20S = queryGrids(aboveLat=-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd region for SST in Northern Atlantic, as in Promet (2008).\n",
    "poly_NAtlantic = [list(reversed(\n",
    "    [ [-100,0], [-100,45],[-100,89], [-40, 89],[20,89],[20,45],[20,0], [-40,0], [-100,0]]))]\n",
    "grid_df_NAtlantic = getGridIds(poly_NAtlantic)\n",
    "grid_ids_NAtlantic = grid_df_NAtlantic.id_grid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryScores(this_variable, this_grid_df):\n",
    "    # Query data anomalies\n",
    "    anom_df = queryAnom(this_variable, this_grid_df)\n",
    "    # Get Principal Component Scores\n",
    "    X_df = anom_df.pivot(index='date', columns='id_grid', values=this_variable)\n",
    "    pca = PCA(n_components=3)\n",
    "    df_scores = pd.DataFrame(pca.fit_transform(X_df), \n",
    "                             columns=['PC1_%s' % (this_variable), \n",
    "                                      'PC2_%s' % (this_variable), \n",
    "                                      'PC3_%s' % (this_variable)],\n",
    "                             index=X_df.index)\n",
    "    return df_scores\n",
    "\n",
    "scores_z70 = queryScores(this_variable='z70', this_grid_df=grid_df_20N)\n",
    "scores_ci = queryScores(this_variable='ci', this_grid_df=grid_df_20N)\n",
    "scores_sst = queryScores(this_variable='sst', this_grid_df=grid_df_20S)\n",
    "scores_sst_NAtl = queryScores(this_variable='sst', this_grid_df=grid_df_NAtlantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_sst_NAtl = scores_sst_NAtl.rename(columns={\"PC1_sst\": \"PC1_sstna\",\n",
    "                                                   \"PC2_sst\": \"PC2_sstna\",\n",
    "                                                   \"PC3_sst\": \"PC3_sstna\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 38 entries, 1979-10-01 to 2016-10-01\n",
      "Data columns (total 4 columns):\n",
      "PC1_ci    38 non-null float64\n",
      "PC2_ci    38 non-null float64\n",
      "PC3_ci    38 non-null float64\n",
      "month     38 non-null int64\n",
      "dtypes: float64(3), int64(1)\n",
      "memory usage: 1.5 KB\n"
     ]
    }
   ],
   "source": [
    "P03_df = scores_ci.assign(month=list(map(lambda x: x.month, scores_ci.index))).query('month == 10')\n",
    "P03_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.49539095],\n",
       "       [-0.49539095,  1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(P03_df.PC1_ci[:-1], msl_df.NAO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.43572617],\n",
       "       [-0.43572617,  1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P04_df = scores_z70.assign(month=list(map(lambda x: x.month, scores_z70.index))).query('month == 10')\n",
    "np.corrcoef(P04_df.PC2_z70[:-1], msl_df.NAO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.04698433],\n",
       "       [ 0.04698433,  1.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P17_df = scores_sst.assign(month=list(map(lambda x: x.month, scores_sst.index))).query('month == 9')\n",
    "np.corrcoef(P17_df.PC3_sst[:-1], msl_df.NAO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group all predictors in one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignWyear(df):\n",
    "    res_df = df.assign(\n",
    "    year=list(map(lambda x: x.year, df.date)),\n",
    "    wyear=list(map(lambda x: setWinterYear(x), df.date)), \n",
    "    month=list(map(lambda x: x.month, df.date)))\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        date       PC1_z70       PC2_z70       PC3_z70    PC1_ci    PC2_ci  \\\n",
       "0 1979-01-01  47305.944044 -21384.693316 -20280.483751 -0.069347  0.698022   \n",
       "1 1979-02-01  27377.090406  -5627.629663 -24174.825459 -0.176903  0.691111   \n",
       "2 1979-09-01  18023.465139   2794.736512  -2092.985110  2.963272  1.071392   \n",
       "3 1979-10-01  14187.255820  -8848.225741  -3218.127655  2.152409  0.879826   \n",
       "4 1979-11-01  27520.923158 -14059.658557  -5650.416198  2.057799 -0.180304   \n",
       "\n",
       "     PC3_ci   PC1_sst   PC2_sst   PC3_sst  PC1_sstna  PC2_sstna  PC3_sstna  \\\n",
       "0  1.563147 -3.052552  3.453180 -5.779823   6.061390  -9.033219   4.809590   \n",
       "1  1.377238 -6.587935  8.314599 -7.697487  10.096280  -8.582903   5.170891   \n",
       "2  1.375140  5.315733  5.144099 -0.101496   6.234057  -2.363909   5.491280   \n",
       "3 -0.169622  6.340731  3.405892  3.130245   1.479563  -6.115383   5.599424   \n",
       "4 -0.983038  3.580924  3.571938  7.027206   1.090428  -3.748723  10.074660   \n",
       "\n",
       "   year  wyear  month      Nino  \n",
       "0  1979   1979      1  0.149061  \n",
       "1  1979   1979      2  0.114270  \n",
       "2  1979   1980      9 -0.320141  \n",
       "3  1979   1980     10 -0.224291  \n",
       "4  1979   1980     11 -0.295341  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.merge(left=scores_z70, right=scores_ci, left_index=True, right_index=True).\\\n",
    "pipe(lambda df: pd.merge(df, scores_sst, left_index=True, right_index=True)).\\\n",
    "pipe(lambda df: pd.merge(df, scores_sst_NAtl, left_index=True, right_index=True))\n",
    "scores_df.reset_index(level=0, inplace=True)\n",
    "scores_df0 = assignWyear(df=scores_df)\n",
    "nino_df = assignWyear(df=nino_df0)\n",
    "scores_df = pd.merge(scores_df0, nino_df)\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Predictor DataFrame\n",
    "def renCol(x, mon):\n",
    "    if ('PC' in x or 'Nino' in x):\n",
    "        z = '%s_%s' % (x, mon)\n",
    "    else:\n",
    "        z = x\n",
    "    return z\n",
    "\n",
    "def createMondf(this_mon, scores_df):\n",
    "    mon_df = scores_df.query('month == @this_mon')\n",
    "    mon_df.columns = list(map(lambda x: renCol(x, mon=this_mon), list(mon_df)))\n",
    "    mon_df = mon_df.drop(['date','year','month'], axis=1)\n",
    "    return mon_df\n",
    "\n",
    "sep_df = createMondf(this_mon=9, scores_df=scores_df)\n",
    "oct_df = createMondf(this_mon=10, scores_df=scores_df)\n",
    "X_df = pd.merge(sep_df, oct_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 37 entries, 0 to 36\n",
      "Data columns (total 28 columns):\n",
      "wyear           37 non-null int64\n",
      "NAO             37 non-null float64\n",
      "PC1_z70_9       37 non-null float64\n",
      "PC2_z70_9       37 non-null float64\n",
      "PC3_z70_9       37 non-null float64\n",
      "PC1_ci_9        37 non-null float64\n",
      "PC2_ci_9        37 non-null float64\n",
      "PC3_ci_9        37 non-null float64\n",
      "PC1_sst_9       37 non-null float64\n",
      "PC2_sst_9       37 non-null float64\n",
      "PC3_sst_9       37 non-null float64\n",
      "PC1_sstna_9     37 non-null float64\n",
      "PC2_sstna_9     37 non-null float64\n",
      "PC3_sstna_9     37 non-null float64\n",
      "Nino_9          37 non-null float64\n",
      "PC1_z70_10      37 non-null float64\n",
      "PC2_z70_10      37 non-null float64\n",
      "PC3_z70_10      37 non-null float64\n",
      "PC1_ci_10       37 non-null float64\n",
      "PC2_ci_10       37 non-null float64\n",
      "PC3_ci_10       37 non-null float64\n",
      "PC1_sst_10      37 non-null float64\n",
      "PC2_sst_10      37 non-null float64\n",
      "PC3_sst_10      37 non-null float64\n",
      "PC1_sstna_10    37 non-null float64\n",
      "PC2_sstna_10    37 non-null float64\n",
      "PC3_sstna_10    37 non-null float64\n",
      "Nino_10         37 non-null float64\n",
      "dtypes: float64(27), int64(1)\n",
      "memory usage: 8.4 KB\n"
     ]
    }
   ],
   "source": [
    "# Create Regression DataFrame\n",
    "NAO_df = msl_df.drop(columns=['msl1', 'msl2', 'month'])\n",
    "dat_df = pd.merge(NAO_df, X_df)\n",
    "dat_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   wyear         NAO     PC1_z70_9    PC2_z70_9     PC3_z70_9  PC1_ci_9  \\\n",
       "0   1980 -251.348252  18023.465139  2794.736512  -2092.985110  2.963272   \n",
       "1   1981  562.276609  -5422.104718  9689.567172   5922.630486  0.101697   \n",
       "2   1982 -713.419876  19744.941093 -8460.604205   1635.209243 -0.538567   \n",
       "3   1983  721.211563 -14530.470578  8700.189280  -4888.437956 -0.840921   \n",
       "4   1984  551.105864  -5774.518779  2361.237107  13897.025591  0.980549   \n",
       "\n",
       "   PC2_ci_9  PC3_ci_9  PC1_sst_9  PC2_sst_9    ...     PC1_ci_10  PC2_ci_10  \\\n",
       "0  1.071392  1.375140   5.315733   5.144099    ...      2.152409   0.879826   \n",
       "1  0.728209  0.115510  -3.156064   0.330398    ...      0.352610   0.479747   \n",
       "2  1.527346 -1.105449  -4.273700   2.978050    ...      0.624417   0.928135   \n",
       "3  1.564581 -0.486861  19.597934   7.319275    ...     -1.098517   1.081049   \n",
       "4  0.753583  0.899558   2.394603  -2.069533    ...      1.588658  -0.114038   \n",
       "\n",
       "   PC3_ci_10  PC1_sst_10  PC2_sst_10  PC3_sst_10  PC1_sstna_10  PC2_sstna_10  \\\n",
       "0  -0.169622    6.340731    3.405892    3.130245      1.479563     -6.115383   \n",
       "1  -0.325371   -4.666931    3.319573   -0.769914      0.501719     -5.743483   \n",
       "2  -0.169243   -5.718029    3.198751   -6.356472      7.601766     -1.296884   \n",
       "3   0.334776   27.178280    9.416390    2.033980     -8.193469     -1.592295   \n",
       "4   0.513688   -3.563558   -3.381978   18.225814     -5.606292      0.579888   \n",
       "\n",
       "   PC3_sstna_10   Nino_10  \n",
       "0      5.599424 -0.224291  \n",
       "1      5.634331  0.163475  \n",
       "2      5.296588  0.101910  \n",
       "3     -6.993783 -1.708226  \n",
       "4     -1.639826  0.772114  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = skl_lm.LinearRegression()\n",
    "X = dat_df[['PC1_ci_10', \n",
    "            'PC2_z70_10',\n",
    "            'PC3_sst_9']].as_matrix()\n",
    "y = dat_df.NAO\n",
    "regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50037140298348137"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmasson/anaconda3/envs/winter_predictor/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning:\n",
      "\n",
      "The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>NAO</td>       <th>  R-squared:         </th> <td>   0.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.02</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 11 Mar 2018</td> <th>  Prob (F-statistic):</th> <td>3.63e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:29:17</td>     <th>  Log-Likelihood:    </th> <td> -279.32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    37</td>      <th>  AIC:               </th> <td>   566.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    33</td>      <th>  BIC:               </th> <td>   573.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>    3.6814</td> <td>   80.217</td> <td>    0.046</td> <td> 0.964</td> <td> -159.521</td> <td>  166.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC1_ci_10</th>  <td> -289.4934</td> <td>   64.195</td> <td>   -4.510</td> <td> 0.000</td> <td> -420.099</td> <td> -158.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC2_z70_10</th> <td>   -0.0208</td> <td>    0.007</td> <td>   -2.909</td> <td> 0.006</td> <td>   -0.035</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC3_sst_9</th>  <td>   31.2633</td> <td>   11.542</td> <td>    2.709</td> <td> 0.011</td> <td>    7.781</td> <td>   54.746</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.213</td> <th>  Durbin-Watson:     </th> <td>   2.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.331</td> <th>  Jarque-Bera (JB):  </th> <td>   1.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.359</td> <th>  Prob(JB):          </th> <td>   0.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.226</td> <th>  Cond. No.          </th> <td>1.14e+04</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    NAO   R-squared:                       0.500\n",
       "Model:                            OLS   Adj. R-squared:                  0.455\n",
       "Method:                 Least Squares   F-statistic:                     11.02\n",
       "Date:                Sun, 11 Mar 2018   Prob (F-statistic):           3.63e-05\n",
       "Time:                        13:29:17   Log-Likelihood:                -279.32\n",
       "No. Observations:                  37   AIC:                             566.6\n",
       "Df Residuals:                      33   BIC:                             573.1\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      3.6814     80.217      0.046      0.964    -159.521     166.884\n",
       "PC1_ci_10   -289.4934     64.195     -4.510      0.000    -420.099    -158.887\n",
       "PC2_z70_10    -0.0208      0.007     -2.909      0.006      -0.035      -0.006\n",
       "PC3_sst_9     31.2633     11.542      2.709      0.011       7.781      54.746\n",
       "==============================================================================\n",
       "Omnibus:                        2.213   Durbin-Watson:                   2.305\n",
       "Prob(Omnibus):                  0.331   Jarque-Bera (JB):                1.717\n",
       "Skew:                          -0.359   Prob(JB):                        0.424\n",
       "Kurtosis:                       2.226   Cond. No.                     1.14e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.14e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = smf.ols('NAO ~ PC1_ci_10 + PC2_z70_10 + PC3_sst_9', dat_df).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Overfitted Model:\n",
    "#est = smf.ols('NAO ~ PC1_z70_9 + PC2_z70_9 + PC3_z70_9 + PC1_ci_9 + PC2_ci_9 + PC3_ci_9 + PC1_sst_9 + PC2_sst_9 + PC3_sst_9 + PC1_z70_10 + PC2_z70_10 + PC3_z70_10 + PC1_ci_10 + PC2_ci_10 + PC3_ci_10 + PC1_sst_10 + PC2_sst_10 + PC3_sst_10', dat_df).fit()\n",
    "#est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization / Lasso Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictors:\n",
    "# 'NAO ~ PC1_ci_10 + PC2_z70_10 + PC3_sst_9' # Wang\n",
    "predNames = np.array(['PC1_z70_9',\n",
    " 'PC2_z70_9',\n",
    " 'PC3_z70_9', # selected by Lasso\n",
    " 'PC1_ci_9',\n",
    " 'PC2_ci_9',\n",
    " 'PC3_ci_9',\n",
    " 'PC1_sst_9',\n",
    " 'PC2_sst_9',\n",
    " 'PC3_sst_9', # selected by Lasso\n",
    " 'PC1_z70_10', # selected by Lasso \n",
    " 'PC2_z70_10', # selected by Lasso & as in Wang et al. 2010\n",
    " 'PC3_z70_10',\n",
    " 'PC1_ci_10', # selected by Lasso & as in Wang et al. 2010\n",
    " 'PC2_ci_10',\n",
    " 'PC3_ci_10',\n",
    " 'PC1_sst_10',\n",
    " 'PC2_sst_10',\n",
    " 'PC3_sst_10',\n",
    " 'PC1_sstna_10','PC2_sstna_10','PC3_sstna_10',\n",
    "                      'Nino_9', 'Nino_10'])\n",
    "X = dat_df[predNames].as_matrix()\n",
    "# Target Variables:\n",
    "y = dat_df.NAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Before applying the Lasso, it is necessary to standardize the predictor\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_stan = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -0.            0.           79.24917277   -0.           -0.            0.\n",
      "   -0.           -0.            0.           -0.          -92.0394126     0.\n",
      " -178.33922105   -0.           -0.           -0.           -0.            0.\n",
      "   -0.            0.           -0.            0.            0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression with fixed penalty term lambda=150:\n",
    "# We see that all predictors but three have been shrunk to null:\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=150)\n",
    "clf.fit(X_stan, y)\n",
    "print(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.855260729962339"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to find the optimal penalty parameter alpha,\n",
    "# use Cross-validated Lasso\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC\n",
    "#modlcv = LassoLarsIC(criterion='aic')\n",
    "modlcv = LassoCV(cv=3, n_alphas=10000,max_iter=10000)\n",
    "modlcv.fit(X_stan, y)\n",
    "alpha = modlcv.alpha_\n",
    "alpha # Optimal penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.        ,    0.        ,  119.82545763,    0.        ,\n",
       "         -0.        ,    0.        ,   -0.        ,   -0.        ,\n",
       "         23.50774767,   -2.24653301, -155.2916353 ,    0.        ,\n",
       "       -267.45638045,    0.        ,  -10.76823728,   -0.        ,\n",
       "          0.        ,    0.        ,  -64.43287177,    0.        ,\n",
       "         -0.        ,    0.        ,    0.        ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-zero predictors:\n",
    "modlcv.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51554966157004301"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model R^2 :\n",
    "modlcv.score(X_stan, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         coef          pred     absCoef\n",
       "4 -267.456380     PC1_ci_10  267.456380\n",
       "3 -155.291635    PC2_z70_10  155.291635\n",
       "0  119.825458     PC3_z70_9  119.825458\n",
       "6  -64.432872  PC1_sstna_10   64.432872\n",
       "1   23.507748     PC3_sst_9   23.507748\n",
       "5  -10.768237     PC3_ci_10   10.768237\n",
       "2   -2.246533    PC1_z70_10    2.246533"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name Of the non-null coefficients:\n",
    "\n",
    "# 'NAO ~ PC1_ci_10 + PC2_z70_10 + PC3_sst_9' # Wang\n",
    "ind = np.array(list(map(lambda x: int(x)!=0, modlcv.coef_)))\n",
    "importance_df = pd.DataFrame({'pred': predNames[ind], \n",
    "                              'coef': modlcv.coef_[ind]})\n",
    "importance_df = importance_df.assign(absCoef=np.absolute(importance_df.coef))\n",
    "# According to the Lasso, the 3 strongest predictors are:\n",
    "# PC3_z70_9, PC2_z70_10, PC1_ci_10\n",
    "importance_df.sort_values('absCoef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the Nino does not seem to play any role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>NAO</td>       <th>  R-squared:         </th> <td>   0.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   10.64</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 11 Mar 2018</td> <th>  Prob (F-statistic):</th> <td>1.34e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:30:08</td>     <th>  Log-Likelihood:    </th> <td> -276.51</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    37</td>      <th>  AIC:               </th> <td>   563.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    32</td>      <th>  BIC:               </th> <td>   571.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   13.0319</td> <td>   75.625</td> <td>    0.172</td> <td> 0.864</td> <td> -141.012</td> <td>  167.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC3_z70_9</th>    <td>    0.0246</td> <td>    0.013</td> <td>    1.848</td> <td> 0.074</td> <td>   -0.003</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC2_z70_10</th>   <td>   -0.0221</td> <td>    0.008</td> <td>   -2.895</td> <td> 0.007</td> <td>   -0.038</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC1_ci_10</th>    <td> -248.3216</td> <td>   53.464</td> <td>   -4.645</td> <td> 0.000</td> <td> -357.224</td> <td> -139.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC1_sstna_10</th> <td>  -29.5680</td> <td>   14.347</td> <td>   -2.061</td> <td> 0.048</td> <td>  -58.791</td> <td>   -0.345</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.568</td> <th>  Durbin-Watson:     </th> <td>   2.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.062</td> <th>  Jarque-Bera (JB):  </th> <td>   2.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.411</td> <th>  Prob(JB):          </th> <td>   0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.943</td> <th>  Cond. No.          </th> <td>1.16e+04</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    NAO   R-squared:                       0.571\n",
       "Model:                            OLS   Adj. R-squared:                  0.517\n",
       "Method:                 Least Squares   F-statistic:                     10.64\n",
       "Date:                Sun, 11 Mar 2018   Prob (F-statistic):           1.34e-05\n",
       "Time:                        13:30:08   Log-Likelihood:                -276.51\n",
       "No. Observations:                  37   AIC:                             563.0\n",
       "Df Residuals:                      32   BIC:                             571.1\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       13.0319     75.625      0.172      0.864    -141.012     167.076\n",
       "PC3_z70_9        0.0246      0.013      1.848      0.074      -0.003       0.052\n",
       "PC2_z70_10      -0.0221      0.008     -2.895      0.007      -0.038      -0.007\n",
       "PC1_ci_10     -248.3216     53.464     -4.645      0.000    -357.224    -139.420\n",
       "PC1_sstna_10   -29.5680     14.347     -2.061      0.048     -58.791      -0.345\n",
       "==============================================================================\n",
       "Omnibus:                        5.568   Durbin-Watson:                   2.292\n",
       "Prob(Omnibus):                  0.062   Jarque-Bera (JB):                2.762\n",
       "Skew:                          -0.411   Prob(JB):                        0.251\n",
       "Kurtosis:                       1.943   Cond. No.                     1.16e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.16e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's repeat the linear regression using the first 4 best predictors suggested by the Lasso:\n",
    "#est = smf.ols('NAO ~ PC1_ci_10 + PC2_z70_10 + PC3_sst_9', dat_df).fit() # Wang\n",
    "est = smf.ols('NAO ~ PC3_z70_9 + PC2_z70_10 + PC1_ci_10 + PC1_sstna_10', dat_df).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(0.571)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step: Do Lasso Regression based on all possible ERA-int variables\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
