{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset, netcdftime, num2date, date2num, date2index\n",
    "from datetime import datetime, timedelta, date\n",
    "import pytz\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap, addcyclic, shiftgrid\n",
    "import pymongo\n",
    "from pymongo import IndexModel, ASCENDING, DESCENDING\n",
    "from pprint import pprint\n",
    "from os import listdir\n",
    "import os\n",
    "import pandas as pd\n",
    "import fnmatch\n",
    "import logging\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "num_cores = 3  # multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insertToMongo(vars):\n",
    "    # Stack all 2d arrays in one multi-d array\n",
    "    this_day = vars['this_day']\n",
    "    lons = vars['lons']\n",
    "    lats = vars['lats']\n",
    "    \n",
    "    DAT = np.array([vars['ci'],   # 0\n",
    "                    vars['sst'],  # 1\n",
    "                    vars['istl1'],# 2\n",
    "                    vars['sp'],   # 3\n",
    "                    vars['stl1'], # 4\n",
    "                    vars['msl'],  # 5\n",
    "                    vars['u10'],  # 6\n",
    "                    vars['v10'],  # 7\n",
    "                    vars['t2m'],  # 8\n",
    "                    vars['d2m'],  # 9\n",
    "                    vars['al'],   # 10\n",
    "                    vars['lcc'],  # 11\n",
    "                    vars['mcc'],  # 12\n",
    "                    vars['hcc'],  # 13\n",
    "                    vars['si10'], # 14\n",
    "                    vars['skt']   # 15\n",
    "                    ])\n",
    "    \n",
    "    # Shift the grid so lons go from -180 to 180 instead of 0 to 360.\n",
    "    DAT_shift, lons_shift = shiftgrid(\n",
    "        lon0=180., datain=DAT, lonsin=lons, start=False)\n",
    "    lon, lat = np.meshgrid(lons_shift, lats)\n",
    "    this_dayhh = datetime.strptime(\n",
    "        \"%s-%s-%sT00:00:00Z\" % (this_day.year, this_day.month, this_day.day), \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    this_year = this_dayhh.year\n",
    "\n",
    "    # Insert into MongoDB\n",
    "    mongo_host_local = 'mongodb://localhost:27017/'\n",
    "    con = pymongo.MongoClient(mongo_host_local)\n",
    "    db = con.ECMWF\n",
    "\n",
    "    #testlon = lon[51:53, 51:52]  # test with a smaller subset\n",
    "    this_id = 0\n",
    "    for (i, j), val in np.ndenumerate(lon):  # lon or testlon): !!!!!!!!!!\n",
    "        this_id += 1\n",
    "        db.ERAINT_monthly.insert_one({\n",
    "            \"id_grid\": this_id,\n",
    "            \"date\": this_dayhh,\n",
    "            \"year\": this_year,\n",
    "            \"ci\": round(DAT_shift[0, i, j], ndigits=2),\n",
    "            \"sst\": round(DAT_shift[1, i, j], ndigits=2),\n",
    "            \"istl1\": round(DAT_shift[2, i, j], ndigits=2),\n",
    "            \"sp\": round(DAT_shift[3, i, j], ndigits=2),\n",
    "            \"stl1\": round(DAT_shift[4, i, j], ndigits=2),\n",
    "            \"msl\": round(DAT_shift[5, i, j], ndigits=2),\n",
    "            \"u10\": round(DAT_shift[6, i, j], ndigits=2),\n",
    "            \"v10\": round(DAT_shift[7, i, j], ndigits=2),\n",
    "            \"t2m\": round(DAT_shift[8, i, j], ndigits=2),\n",
    "            \"d2m\": round(DAT_shift[9, i, j], ndigits=2),\n",
    "            \"al\": round(DAT_shift[10, i, j], ndigits=2),\n",
    "            \"lcc\": round(DAT_shift[11, i, j], ndigits=2),\n",
    "            \"mcc\": round(DAT_shift[12, i, j], ndigits=2),\n",
    "            \"hcc\": round(DAT_shift[13, i, j], ndigits=2),\n",
    "            \"si10\": round(DAT_shift[14, i, j], ndigits=2),\n",
    "            \"skt\": round(DAT_shift[15, i, j], ndigits=2)\n",
    "        })\n",
    "\n",
    "\n",
    "def insertOneDay(this_day, ncfile, DF):\n",
    "    # Choose one arbitrary day\n",
    "    # this_day = days.iloc[0]\n",
    "    logging.info(this_day)\n",
    "    ncfile00 = '%s%s' % (downloadDir, ncfile)\n",
    "    fh = Dataset(ncfile00, mode='r')\n",
    "    lons = fh.variables['longitude'][:]\n",
    "    lats = fh.variables['latitude'][:]\n",
    "    # Extract the data for this day out of the nc file\n",
    "    times = DF[DF.date == this_day].time\n",
    "    ind = date2index(dates=times.tolist(), nctime=fh.variables['time'])\n",
    "\n",
    "    vars = {'ci': fh.variables['ci'][ind], # Sea-ice cover [0-1]\n",
    "            'sst': fh.variables['sst'][ind], # Sea surface temperature [K]\n",
    "            'istl1': fh.variables['istl1'][ind], # Ice temp layer1 [K]\n",
    "            'sp': fh.variables['sp'][ind], # Surface pressure [Pa]\n",
    "            'stl1': fh.variables['stl1'][ind], # Soil temp lev1 [K]\n",
    "            'msl': fh.variables['msl'][ind], # Mean SLP [Pa]\n",
    "            'u10': fh.variables['u10'][ind], # wind-u [m/s]\n",
    "            'v10': fh.variables['v10'][ind],\n",
    "            't2m': fh.variables['t2m'][ind], # 2m temp [K]\n",
    "            'd2m': fh.variables['d2m'][ind], # 2 metre dewpoint temperature[K]\n",
    "            'al': fh.variables['al'][ind], # Surface albedo [0-1]\n",
    "            'lcc': fh.variables['lcc'][ind], # Low cloud cover [0-1]\n",
    "            'mcc': fh.variables['mcc'][ind], # Medium cloud cover [0-1]\n",
    "            'hcc': fh.variables['hcc'][ind], # High cloud cover [0-1]\n",
    "            'si10': fh.variables['si10'][ind], # 10m wind speed [m/s]\n",
    "            'skt': fh.variables['skt'][ind], # Skin temperature [K]\n",
    "            'lons': lons,\n",
    "            'lats': lats,\n",
    "            'this_day': this_day}\n",
    "\n",
    "    insertToMongo(vars)\n",
    "    if (this_day == date(1980, 1, 2)):\n",
    "        # Setup the indexes just once\n",
    "        doIndexing()\n",
    "\n",
    "    fh.close()\n",
    "\n",
    "\n",
    "def getDatesDF(nc_file):  # insertFile(nc_file):\n",
    "    logging.info(\"Inserting %s\" % (nc_file))\n",
    "    nc_file00 = '%s%s' % (downloadDir, nc_file)\n",
    "    fh = Dataset(nc_file00, mode='r')\n",
    "    nctime = fh.variables['time'][:]\n",
    "    t_unit = fh.variables['time'].units\n",
    "    fh.close()\n",
    "    time = num2date(nctime, units=t_unit)\n",
    "    # Create a data frame\n",
    "    df = pd.DataFrame({'time': time})\n",
    "    df = df.assign(date=df.time.dt.date)\n",
    "    # Do some aggregation\n",
    "    gdf = pd.DataFrame(df.groupby('date').size().rename('ndoc')).reset_index()\n",
    "    df2 = pd.merge(left=df, right=gdf, on=\"date\")\n",
    "    # exclude datesInMongo (data already ingested)\n",
    "    DF = df2[~pd.to_datetime(df2.date).isin(datesInMongo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'era-int_multivarm1_1979-01-01_to_2017-08-31.nc'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloadDir = '/home/dmasson/data/era-interim/'\n",
    "files00 = listdir(downloadDir)\n",
    "files = fnmatch.filter(files00, '*multivarm1*.nc')\n",
    "files.sort()\n",
    "this_file = files[0]\n",
    "this_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "DF = getDatesDF(this_file)\n",
    "DF = getDatesDF(this_file)\n",
    "DF\n",
    "days = DF.date.drop_duplicates()\n",
    "days\n",
    "this_day = days[1]\n",
    "this_day\n",
    "ncfile = this_file\n",
    "nc_file = this_file\n",
    "logging.info(\"Inserting %s\" % (nc_file))\n",
    "nc_file00 = '%s%s' % (downloadDir, nc_file)\n",
    "fh = Dataset(nc_file00, mode='r')\n",
    "nctime = fh.variables['time'][:]\n",
    "t_unit = fh.variables['time'].units\n",
    "fh.close()\n",
    "logging.info(this_day)\n",
    "ncfile00 = '%s%s' % (downloadDir, ncfile)\n",
    "fh = Dataset(ncfile00, mode='r')\n",
    "lons = fh.variables['longitude'][:]\n",
    "lats = fh.variables['latitude'][:]\n",
    "times = DF[DF.date == this_day].time\n",
    "ind = date2index(dates=times.tolist(), nctime=fh.variables['time'])\n",
    "import codecs, os;__pyfile = codecs.open('''/tmp/py3002rjD''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/py3002rjD''');exec(compile(__code, '''/home/dmasson/CloudStation/code/winter_predictor/era_interim_insert.py''', 'exec'));\n",
    "vars\n",
    "this_day\n",
    "this_day = vars['this_day']\n",
    "lons = vars['lons']\n",
    "lats = vars['lats']\n",
    "lons\n",
    "sizeof(vars['ci'])\n",
    "size(vars['ci'])\n",
    "vars['ci'].size\n",
    "vars['ci'].shape\n",
    "vars['ci'][1,3]\n",
    "vars['ci'][1:4,3]\n",
    "import readline\n",
    "for i in range(readline.get_current_history_length()):\n",
    "    print readline.get_history_item(i + 1)\n",
    "import codecs, os;__pyfile = codecs.open('''/tmp/py30025nc''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/py30025nc''');exec(compile(__code, '''/home/dmasson/CloudStation/code/winter_predictor/era_interim_insert.py''', 'exec'));\n",
    "import codecs, os;__pyfile = codecs.open('''/tmp/py3002GAL''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/py3002GAL''');exec(compile(__code, '''/home/dmasson/CloudStation/code/winter_predictor/era_interim_insert.py''', 'exec'));\n",
    "import codecs, os;__pyfile = codecs.open('''/tmp/py3002UEk''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/py3002UEk''');exec(compile(__code, '''/home/dmasson/CloudStation/code/winter_predictor/era_interim_insert.py''', 'exec'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
